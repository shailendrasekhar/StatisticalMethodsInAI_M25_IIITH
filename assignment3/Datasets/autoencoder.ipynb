{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b252fdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/detour/anaconda3/envs/smai/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/detour/anaconda3/envs/smai/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-10-16 12:14:28.455264: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-16 12:14:28.701382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-16 12:14:30.035747: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import wandb.sdk.wandb_settings as wandb_settings\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import auc, precision_recall_fscore_support, roc_curve, precision_recall_curve, f1_score\n",
    "import gc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3712a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    \"\"\"Base class for activation functions.\"\"\"\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "class Identity(Activation):\n",
    "    \"\"\"Identity activation function (no activation).\"\"\"\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output\n",
    "\n",
    "class ReLU(Activation):\n",
    "    \"\"\"ReLU activation function.\"\"\"\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * (self.input > 0)\n",
    "\n",
    "class Tanh(Activation):\n",
    "    \"\"\"Tanh activation function.\"\"\"\n",
    "    def forward(self, x):\n",
    "        self.output = np.tanh(x)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * (1 - self.output**2)\n",
    "\n",
    "class Sigmoid(Activation):\n",
    "    \"\"\"Sigmoid activation function.\"\"\"\n",
    "    def forward(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * (self.output * (1 - self.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5253ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \"\"\"  Fully connected linear layer with activation function.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, activation=Identity()):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        if isinstance(activation, ReLU):\n",
    "            limit = np.sqrt(6 / (input_dim))\n",
    "        else:\n",
    "            limit = np.sqrt(6 / (input_dim + output_dim))\n",
    "        self.activation = activation\n",
    "        self.weights = np.random.uniform(-limit, limit, (input_dim, output_dim))\n",
    "        self.biases = np.zeros((1, output_dim))\n",
    "        self.input = None\n",
    "        self.output = None   \n",
    "        self.grad_weights = np.zeros_like(self.weights)\n",
    "        self.grad_biases = np.zeros_like(self.biases)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass \"\"\"\n",
    "        self.input = x\n",
    "        pre_activation = x @ self.weights + self.biases\n",
    "        self.output = self.activation.forward(pre_activation)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        \"\"\" Backward pass \"\"\"\n",
    "        grad_pre_activation = self.activation.backward(grad_output)\n",
    "        self.grad_weights += self.input.T @ grad_pre_activation\n",
    "        self.grad_biases += np.sum(grad_pre_activation, axis=0, keepdims=True)\n",
    "        grad_input = grad_pre_activation @ self.weights.T\n",
    "        return grad_input\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"Update parameters using accumulated gradients\"\"\"\n",
    "        self.weights -= learning_rate * self.grad_weights\n",
    "        self.biases -= learning_rate * self.grad_biases\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Reset accumulated gradients to zero\"\"\"\n",
    "        self.grad_weights = np.zeros_like(self.weights)\n",
    "        self.grad_biases = np.zeros_like(self.biases)\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"Returns the layer's parameters in a dictionary.\"\"\"\n",
    "        return {'weights': self.weights, 'biases': self.biases}\n",
    "\n",
    "    def set_params(self, params):\n",
    "        \"\"\"Sets the layer's parameters from a dictionary.\"\"\"\n",
    "        self.weights = params['weights']\n",
    "        self.biases = params['biases']\n",
    "    \n",
    "    def set_parameters_dtype(self, dtype):\n",
    "        \"\"\"Casts the weights and biases to a specified data type.\"\"\"\n",
    "        self.weights = self.weights.astype(dtype)\n",
    "        self.biases = self.biases.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a13f9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    \"\"\"Base class for loss functions.\"\"\"\n",
    "    def forward(self, y_pred, y_true):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self, y_pred, y_true):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class MSE(Loss):\n",
    "    \"\"\"Mean Squared Error Loss.\"\"\"\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "    \n",
    "    def backward(self, y_pred, y_true):\n",
    "        return 2 * (y_pred - y_true) / y_true.shape[0]\n",
    "\n",
    "class BCE(Loss):\n",
    "    \"\"\"Binary Cross Entropy Loss.\"\"\"\n",
    "    def forward(self, y_pred, y_true):\n",
    "        epsilon = 1e-9\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def backward(self, y_pred, y_true):\n",
    "        epsilon = 1e-9\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return (y_pred - y_true) / (y_pred * (1 - y_pred)) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156191a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"A neural network model composed of a list of layers.\"\"\"\n",
    "    def __init__(self, layers, loss_fn):\n",
    "        self.layers = layers\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Sequentially execute the forward pass in each layer.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        \"\"\"Sequentially execute the backward pass in reverse order.\"\"\"\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "        return grad\n",
    "\n",
    "    def train(self, x, y):\n",
    "        \"\"\"Perform a single training step: forward, loss, backward.\"\"\"\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn.forward(y_pred, y)\n",
    "        initial_grad = self.loss_fn.backward(y_pred, y)\n",
    "        self.backward(initial_grad)\n",
    "        return loss\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Reset gradients in all layers to zero.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.zero_grad()\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"Update parameters in all layers and then zero the gradients.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.update(learning_rate)\n",
    "        self.zero_grad()\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Perform a forward pass to get a prediction.\"\"\"\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        \"\"\" Gets a list of all parameters (weights and biases) from all layers. \"\"\"\n",
    "        return [layer.get_params() for layer in self.layers]\n",
    "    \n",
    "    def set_parameters_dtype(self, dtype):\n",
    "        \"\"\"Casts the parameters of all layers to a specified data type.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.set_parameters_dtype(dtype)\n",
    "\n",
    "    def set_parameters(self, params_list):\n",
    "        \"\"\" Sets the parameters for all layers from a provided list. \"\"\"\n",
    "        if len(params_list) != len(self.layers):\n",
    "            raise ValueError(\"The number of parameter sets must match the number of layers.\")\n",
    "        for layer, params in zip(self.layers, params_list):\n",
    "            layer.set_params(params)\n",
    "\n",
    "    def save_to(self, path):\n",
    "        \"\"\"Save all model parameters to a .npz file.\"\"\"\n",
    "        params = {f'layer_{i}_{k}': v for i, l in enumerate(self.layers) \n",
    "                  for k, v in l.get_params().items()}\n",
    "        np.savez(path, **params)\n",
    "        return\n",
    "\n",
    "    def load_from(self, path):\n",
    "        \"\"\"Load model parameters from a .npz file.\"\"\"\n",
    "        data = np.load(path)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            weights = data[f'layer_{i}_weights']\n",
    "            biases = data[f'layer_{i}_biases']\n",
    "            \n",
    "            if weights.shape != layer.weights.shape or biases.shape != layer.biases.shape:\n",
    "                raise ValueError(\n",
    "                    f\"Shape mismatch in layer {i}. Expected weights {layer.weights.shape} \"\n",
    "                    f\"and biases {layer.biases.shape}, but got {weights.shape} and {biases.shape}.\"\n",
    "                )\n",
    "            layer.set_params({'weights': weights, 'biases': biases})\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb962e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAutoencoder:\n",
    "    \"\"\"\n",
    "    An MLP-based Autoencoder built using the existing Model class.\"\"\"\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dims):\n",
    "        encoder_layers = []\n",
    "        last_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            encoder_layers.append(Linear(last_dim, h_dim, ReLU()))\n",
    "            last_dim = h_dim\n",
    "        encoder_layers.append(Linear(last_dim, latent_dim, ReLU()))\n",
    "        self.encoder = Model(layers=encoder_layers, loss_fn=MSE())\n",
    "        decoder_layers = []\n",
    "        last_dim = latent_dim\n",
    "        for h_dim in reversed(hidden_dims):\n",
    "            decoder_layers.append(Linear(last_dim, h_dim, ReLU()))\n",
    "            last_dim = h_dim\n",
    "        decoder_layers.append(Linear(last_dim, input_dim, Sigmoid()))\n",
    "        self.decoder = Model(layers=decoder_layers, loss_fn=MSE())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"A full forward pass: input -> latent space -> reconstruction.\"\"\" \n",
    "        latent_representation = self.encoder.forward(x)\n",
    "        reconstructed_x = self.decoder.forward(latent_representation)\n",
    "        return reconstructed_x\n",
    "\n",
    "    def train_step(self, x, learning_rate):\n",
    "        \"\"\" Performs a single, complete training step: forward, loss, backward, and update. \"\"\"\n",
    "        reconstructed_x = self.forward(x)\n",
    "        loss = self.decoder.loss_fn.forward(reconstructed_x, x)\n",
    "        grad = self.decoder.loss_fn.backward(reconstructed_x, x)\n",
    "        grad = self.decoder.backward(grad)\n",
    "        self.encoder.backward(grad)\n",
    "        self.encoder.update(learning_rate)\n",
    "        self.decoder.update(learning_rate)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6f7c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderTrainer:\n",
    "    \"\"\" Handles the training and evaluation of the MLPAutoencoder on the MNIST dataset.\"\"\"\n",
    "    def __init__(self, autoencoder, config,username):\n",
    "        self.autoencoder = autoencoder\n",
    "        self.config = config\n",
    "        self._load_data()\n",
    "        self.username = username\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Loads and preprocesses the MNIST dataset.\"\"\"\n",
    "        (X_train_raw, _), (X_test_raw, y_test_raw) = mnist.load_data()\n",
    "        self.X_train = X_train_raw.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "        self.X_test = X_test_raw.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "        self.y_test_raw = y_test_raw\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Training loop for the autoencoder.\"\"\"\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            epoch_loss = 0\n",
    "            pbar = tqdm(range(0, len(self.X_train), self.config[\"batch_size\"]), \n",
    "                        desc=f\"Epoch {epoch+1}/{self.config['epochs']}\")\n",
    "            \n",
    "            for i in pbar:\n",
    "                x_batch = self.X_train[i : i + self.config[\"batch_size\"]]\n",
    "                loss = self.autoencoder.train_step(x_batch, self.config[\"learning_rate\"])\n",
    "                epoch_loss += loss\n",
    "                pbar.set_postfix({\"loss\": f\"{loss:.4f}\"})\n",
    "\n",
    "            avg_loss = epoch_loss / (len(self.X_train) / self.config[\"batch_size\"])\n",
    "            print(f\"Epoch {epoch+1} Average Loss: {avg_loss:.4f}\")\n",
    "        return \n",
    "    \n",
    "    \n",
    "    def _watermark(self, ax):\n",
    "        \"\"\"Adds a watermark to the plot axis.\"\"\"\n",
    "        ax.text(0.98, 0.98, self.username, ha='right', va='top', \n",
    "        transform=ax.transAxes, fontsize=10, color='black', alpha=0.6)\n",
    "\n",
    "    def visualize_results(self):\n",
    "        \"\"\" Visualizes the performance by comparing original vs. reconstructed images.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
    "        fig.suptitle(\"Original vs. Reconstructed Images\", fontsize=16)\n",
    "        \n",
    "        digit_images = []\n",
    "        for i in range(10):\n",
    "            idx = np.where(self.y_test_raw == i)[0][0]\n",
    "            digit_images.append(self.X_test[idx])\n",
    "\n",
    "        for i, image in enumerate(digit_images):\n",
    "            reconstruction = self.autoencoder.forward(image.reshape(1, -1))\n",
    "            ax_orig = axes[0, i]\n",
    "            ax_orig.imshow(image.reshape(28, 28), cmap='gray')\n",
    "            ax_orig.axis('off')\n",
    "            ax_recon = axes[1, i]\n",
    "            ax_recon.imshow(reconstruction.reshape(28, 28), cmap='gray')\n",
    "            ax_recon.axis('off')\n",
    "\n",
    "            if i == 0:\n",
    "                ax_orig.set_ylabel('Original', fontsize=12)\n",
    "                ax_recon.set_ylabel('Reconstructed', fontsize=12)\n",
    "            ax_orig.set_title(f\"Digit: {i}\")\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        self._watermark(plt.gca())\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Runs the full training and evaluation pipeline.\"\"\"\n",
    "        self.train()\n",
    "        self.visualize_results()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f19cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150: 100%|██████████| 235/235 [00:04<00:00, 49.97it/s, loss=0.0509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Loss: 0.0573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150: 100%|██████████| 235/235 [00:04<00:00, 47.35it/s, loss=0.0391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/150: 100%|██████████| 235/235 [00:04<00:00, 55.40it/s, loss=0.0332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150: 100%|██████████| 235/235 [00:04<00:00, 55.34it/s, loss=0.0321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Loss: 0.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150: 100%|██████████| 235/235 [00:04<00:00, 55.82it/s, loss=0.0300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/150: 100%|██████████| 235/235 [00:04<00:00, 55.69it/s, loss=0.0260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/150: 100%|██████████| 235/235 [00:04<00:00, 50.48it/s, loss=0.0229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/150: 100%|██████████| 235/235 [00:04<00:00, 51.18it/s, loss=0.0239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/150: 100%|██████████| 235/235 [00:04<00:00, 49.51it/s, loss=0.0246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/150: 100%|██████████| 235/235 [00:04<00:00, 55.84it/s, loss=0.0218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/150: 100%|██████████| 235/235 [00:04<00:00, 52.45it/s, loss=0.0190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/150: 100%|██████████| 235/235 [00:04<00:00, 53.84it/s, loss=0.0201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/150: 100%|██████████| 235/235 [00:04<00:00, 54.02it/s, loss=0.0190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/150: 100%|██████████| 235/235 [00:04<00:00, 54.28it/s, loss=0.0198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/150: 100%|██████████| 235/235 [00:04<00:00, 53.53it/s, loss=0.0196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/150: 100%|██████████| 235/235 [00:04<00:00, 53.12it/s, loss=0.0184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Loss: 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/150: 100%|██████████| 235/235 [00:04<00:00, 55.40it/s, loss=0.0183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/150: 100%|██████████| 235/235 [00:04<00:00, 54.29it/s, loss=0.0214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/150: 100%|██████████| 235/235 [00:04<00:00, 50.32it/s, loss=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/150: 100%|██████████| 235/235 [00:04<00:00, 55.18it/s, loss=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/150: 100%|██████████| 235/235 [00:04<00:00, 54.57it/s, loss=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/150: 100%|██████████| 235/235 [00:04<00:00, 56.69it/s, loss=0.0153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/150: 100%|██████████| 235/235 [00:04<00:00, 48.11it/s, loss=0.0202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Average Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/150: 100%|██████████| 235/235 [00:04<00:00, 53.59it/s, loss=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Average Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/150: 100%|██████████| 235/235 [00:04<00:00, 52.66it/s, loss=0.0160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Average Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/150: 100%|██████████| 235/235 [00:04<00:00, 53.07it/s, loss=0.0174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Average Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/150: 100%|██████████| 235/235 [00:04<00:00, 53.28it/s, loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Average Loss: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/150: 100%|██████████| 235/235 [00:04<00:00, 54.80it/s, loss=0.0150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Average Loss: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/150: 100%|██████████| 235/235 [00:04<00:00, 53.34it/s, loss=0.0153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Average Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/150: 100%|██████████| 235/235 [00:04<00:00, 52.98it/s, loss=0.0152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Average Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/150: 100%|██████████| 235/235 [00:04<00:00, 54.67it/s, loss=0.0143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Average Loss: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/150: 100%|██████████| 235/235 [00:04<00:00, 53.60it/s, loss=0.0128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Average Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/150: 100%|██████████| 235/235 [00:04<00:00, 52.90it/s, loss=0.0151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Average Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/150: 100%|██████████| 235/235 [00:04<00:00, 51.63it/s, loss=0.0153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Average Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/150: 100%|██████████| 235/235 [00:04<00:00, 52.79it/s, loss=0.0136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Average Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/150: 100%|██████████| 235/235 [00:04<00:00, 54.37it/s, loss=0.0145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Average Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/150: 100%|██████████| 235/235 [00:04<00:00, 52.41it/s, loss=0.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Average Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/150: 100%|██████████| 235/235 [00:04<00:00, 51.81it/s, loss=0.0160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Average Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/150: 100%|██████████| 235/235 [00:04<00:00, 53.55it/s, loss=0.0139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Average Loss: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/150: 100%|██████████| 235/235 [00:04<00:00, 53.86it/s, loss=0.0126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Average Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/150: 100%|██████████| 235/235 [00:04<00:00, 51.52it/s, loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Average Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/150: 100%|██████████| 235/235 [00:04<00:00, 50.32it/s, loss=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Average Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/150: 100%|██████████| 235/235 [00:04<00:00, 51.58it/s, loss=0.0124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Average Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/150: 100%|██████████| 235/235 [00:04<00:00, 50.62it/s, loss=0.0121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Average Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/150: 100%|██████████| 235/235 [00:04<00:00, 52.91it/s, loss=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Average Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/150: 100%|██████████| 235/235 [00:05<00:00, 45.72it/s, loss=0.0121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Average Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/150: 100%|██████████| 235/235 [00:04<00:00, 48.77it/s, loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Average Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/150: 100%|██████████| 235/235 [00:04<00:00, 53.10it/s, loss=0.0131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Average Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/150: 100%|██████████| 235/235 [00:04<00:00, 52.09it/s, loss=0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Average Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/150: 100%|██████████| 235/235 [00:04<00:00, 52.18it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Average Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/150: 100%|██████████| 235/235 [00:04<00:00, 48.96it/s, loss=0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Average Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/150: 100%|██████████| 235/235 [00:04<00:00, 51.79it/s, loss=0.0135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Average Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/150: 100%|██████████| 235/235 [00:04<00:00, 51.99it/s, loss=0.0141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Average Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/150: 100%|██████████| 235/235 [00:04<00:00, 52.27it/s, loss=0.0139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Average Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/150: 100%|██████████| 235/235 [00:04<00:00, 50.75it/s, loss=0.0129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Average Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/150: 100%|██████████| 235/235 [00:04<00:00, 53.32it/s, loss=0.0126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Average Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/150: 100%|██████████| 235/235 [00:04<00:00, 51.94it/s, loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Average Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/150: 100%|██████████| 235/235 [00:04<00:00, 51.31it/s, loss=0.0114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Average Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/150: 100%|██████████| 235/235 [00:04<00:00, 50.75it/s, loss=0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Average Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/150: 100%|██████████| 235/235 [00:04<00:00, 50.18it/s, loss=0.0126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Average Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/150: 100%|██████████| 235/235 [00:04<00:00, 51.23it/s, loss=0.0120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Average Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/150: 100%|██████████| 235/235 [00:04<00:00, 50.61it/s, loss=0.0114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Average Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/150: 100%|██████████| 235/235 [00:04<00:00, 51.54it/s, loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Average Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/150: 100%|██████████| 235/235 [00:04<00:00, 48.79it/s, loss=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Average Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/150: 100%|██████████| 235/235 [00:04<00:00, 50.84it/s, loss=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Average Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/150: 100%|██████████| 235/235 [00:04<00:00, 50.21it/s, loss=0.0123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Average Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/150: 100%|██████████| 235/235 [00:04<00:00, 50.87it/s, loss=0.0104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Average Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/150: 100%|██████████| 235/235 [00:04<00:00, 49.19it/s, loss=0.0113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Average Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/150: 100%|██████████| 235/235 [00:04<00:00, 48.08it/s, loss=0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Average Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/150: 100%|██████████| 235/235 [00:05<00:00, 44.59it/s, loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Average Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/150: 100%|██████████| 235/235 [00:05<00:00, 44.22it/s, loss=0.0115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Average Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/150: 100%|██████████| 235/235 [00:06<00:00, 39.04it/s, loss=0.0123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Average Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/150: 100%|██████████| 235/235 [00:04<00:00, 51.18it/s, loss=0.0103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Average Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/150: 100%|██████████| 235/235 [00:05<00:00, 46.04it/s, loss=0.0102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Average Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/150: 100%|██████████| 235/235 [00:04<00:00, 50.67it/s, loss=0.0113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Average Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/150: 100%|██████████| 235/235 [00:05<00:00, 43.57it/s, loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Average Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/150: 100%|██████████| 235/235 [00:04<00:00, 54.15it/s, loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Average Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/150: 100%|██████████| 235/235 [00:04<00:00, 57.40it/s, loss=0.0110]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Average Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/150: 100%|██████████| 235/235 [00:04<00:00, 52.16it/s, loss=0.0105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Average Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/150: 100%|██████████| 235/235 [00:06<00:00, 35.99it/s, loss=0.0100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Average Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/150: 100%|██████████| 235/235 [00:04<00:00, 52.29it/s, loss=0.0115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Average Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/150: 100%|██████████| 235/235 [00:04<00:00, 51.34it/s, loss=0.0102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Average Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/150: 100%|██████████| 235/235 [00:04<00:00, 53.94it/s, loss=0.0103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Average Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/150: 100%|██████████| 235/235 [00:04<00:00, 56.05it/s, loss=0.0100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Average Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/150: 100%|██████████| 235/235 [00:04<00:00, 47.58it/s, loss=0.0097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Average Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/150: 100%|██████████| 235/235 [00:04<00:00, 50.27it/s, loss=0.0093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Average Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/150: 100%|██████████| 235/235 [00:04<00:00, 56.74it/s, loss=0.0108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Average Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/150: 100%|██████████| 235/235 [00:06<00:00, 38.21it/s, loss=0.0114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Average Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/150: 100%|██████████| 235/235 [00:05<00:00, 42.65it/s, loss=0.0114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Average Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/150: 100%|██████████| 235/235 [00:05<00:00, 40.99it/s, loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Average Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/150: 100%|██████████| 235/235 [00:05<00:00, 45.90it/s, loss=0.0094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Average Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/150: 100%|██████████| 235/235 [00:05<00:00, 46.22it/s, loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Average Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/150: 100%|██████████| 235/235 [00:05<00:00, 42.02it/s, loss=0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Average Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/150: 100%|██████████| 235/235 [00:05<00:00, 39.50it/s, loss=0.0098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Average Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/150: 100%|██████████| 235/235 [00:06<00:00, 38.20it/s, loss=0.0104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Average Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/150: 100%|██████████| 235/235 [00:05<00:00, 44.39it/s, loss=0.0093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Average Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/150: 100%|██████████| 235/235 [00:05<00:00, 41.26it/s, loss=0.0105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Average Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/150: 100%|██████████| 235/235 [00:05<00:00, 43.09it/s, loss=0.0101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Average Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/150: 100%|██████████| 235/235 [00:05<00:00, 44.34it/s, loss=0.0093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Average Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/150: 100%|██████████| 235/235 [00:05<00:00, 45.05it/s, loss=0.0105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Average Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/150: 100%|██████████| 235/235 [00:05<00:00, 44.76it/s, loss=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 Average Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/150: 100%|██████████| 235/235 [00:05<00:00, 42.75it/s, loss=0.0100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 Average Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/150: 100%|██████████| 235/235 [00:05<00:00, 43.80it/s, loss=0.0095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 Average Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/150: 100%|██████████| 235/235 [00:05<00:00, 44.67it/s, loss=0.0106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 Average Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/150: 100%|██████████| 235/235 [00:05<00:00, 45.55it/s, loss=0.0096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Average Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/150: 100%|██████████| 235/235 [00:05<00:00, 43.90it/s, loss=0.0105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 Average Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/150: 100%|██████████| 235/235 [00:05<00:00, 43.05it/s, loss=0.0097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 Average Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/150: 100%|██████████| 235/235 [00:05<00:00, 45.48it/s, loss=0.0107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 Average Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/150: 100%|██████████| 235/235 [00:05<00:00, 43.24it/s, loss=0.0100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 Average Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/150: 100%|██████████| 235/235 [00:04<00:00, 48.32it/s, loss=0.0088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 Average Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/150: 100%|██████████| 235/235 [00:04<00:00, 58.35it/s, loss=0.0087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 Average Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/150: 100%|██████████| 235/235 [00:03<00:00, 63.87it/s, loss=0.0092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 Average Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/150: 100%|██████████| 235/235 [00:04<00:00, 57.50it/s, loss=0.0085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/150: 100%|██████████| 235/235 [00:03<00:00, 61.65it/s, loss=0.0113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 Average Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/150: 100%|██████████| 235/235 [00:03<00:00, 58.83it/s, loss=0.0085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/150: 100%|██████████| 235/235 [00:03<00:00, 59.86it/s, loss=0.0097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/150: 100%|██████████| 235/235 [00:03<00:00, 60.59it/s, loss=0.0097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150: 100%|██████████| 235/235 [00:04<00:00, 56.94it/s, loss=0.0086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150: 100%|██████████| 235/235 [00:03<00:00, 63.01it/s, loss=0.0096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/150: 100%|██████████| 235/235 [00:03<00:00, 64.03it/s, loss=0.0094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/150: 100%|██████████| 235/235 [00:05<00:00, 45.55it/s, loss=0.0097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 Average Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/150: 100%|██████████| 235/235 [00:06<00:00, 37.59it/s, loss=0.0087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 Average Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/150: 100%|██████████| 235/235 [00:05<00:00, 44.58it/s, loss=0.0097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 Average Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/150: 100%|██████████| 235/235 [00:04<00:00, 52.28it/s, loss=0.0089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 Average Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/150: 100%|██████████| 235/235 [00:04<00:00, 50.42it/s, loss=0.0114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 Average Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/150: 100%|██████████| 235/235 [00:05<00:00, 43.88it/s, loss=0.0098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 Average Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/150: 100%|██████████| 235/235 [00:05<00:00, 42.17it/s, loss=0.0082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 Average Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/150: 100%|██████████| 235/235 [00:08<00:00, 29.12it/s, loss=0.0088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 Average Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/150: 100%|██████████| 235/235 [00:05<00:00, 44.08it/s, loss=0.0083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 Average Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/150: 100%|██████████| 235/235 [00:04<00:00, 51.08it/s, loss=0.0087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 Average Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/150: 100%|██████████| 235/235 [00:04<00:00, 52.98it/s, loss=0.0093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 Average Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/150: 100%|██████████| 235/235 [00:04<00:00, 53.35it/s, loss=0.0080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 Average Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/150: 100%|██████████| 235/235 [00:04<00:00, 52.01it/s, loss=0.0096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 Average Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/150: 100%|██████████| 235/235 [00:04<00:00, 49.22it/s, loss=0.0102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 Average Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/150: 100%|██████████| 235/235 [00:04<00:00, 51.24it/s, loss=0.0094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 Average Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/150: 100%|██████████| 235/235 [00:05<00:00, 43.18it/s, loss=0.0085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 Average Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/150: 100%|██████████| 235/235 [00:05<00:00, 42.61it/s, loss=0.0098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 Average Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/150: 100%|██████████| 235/235 [00:05<00:00, 44.35it/s, loss=0.0091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 Average Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/150: 100%|██████████| 235/235 [00:04<00:00, 54.91it/s, loss=0.0099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 Average Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/150: 100%|██████████| 235/235 [00:04<00:00, 56.08it/s, loss=0.0093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 Average Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/150: 100%|██████████| 235/235 [00:05<00:00, 43.46it/s, loss=0.0094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 Average Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/150: 100%|██████████| 235/235 [00:05<00:00, 45.44it/s, loss=0.0092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 Average Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/150: 100%|██████████| 235/235 [00:06<00:00, 38.24it/s, loss=0.0091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 Average Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/150: 100%|██████████| 235/235 [00:05<00:00, 41.29it/s, loss=0.0081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Average Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/150: 100%|██████████| 235/235 [00:06<00:00, 36.55it/s, loss=0.0084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 Average Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/150: 100%|██████████| 235/235 [00:06<00:00, 33.76it/s, loss=0.0094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 Average Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/150: 100%|██████████| 235/235 [00:05<00:00, 43.93it/s, loss=0.0092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 Average Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/150: 100%|██████████| 235/235 [00:06<00:00, 33.84it/s, loss=0.0079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Average Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/150: 100%|██████████| 235/235 [00:05<00:00, 43.22it/s, loss=0.0084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 Average Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/150: 100%|██████████| 235/235 [00:05<00:00, 42.40it/s, loss=0.0082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 Average Loss: 0.0076\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_DIM = 784 \n",
    "LATENT_DIM = 32\n",
    "HIDDEN_DIMS = [256, 128]\n",
    "username = 'reddy.bathula'\n",
    "\n",
    "config = {\"learning_rate\": 0.01, \"epochs\": 150, \"batch_size\": 256}\n",
    "autoencoder = MLPAutoencoder(input_dim=INPUT_DIM, latent_dim=LATENT_DIM, hidden_dims=HIDDEN_DIMS)\n",
    "trainer = AutoencoderTrainer(autoencoder, config, username)\n",
    "trainer.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3b883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49f19cbb",
   "metadata": {},
   "source": [
    "## Anomoly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector:\n",
    "    \"\"\" Handles the entire process of training and evaluating an autoencoder for anomaly detection. \"\"\"\n",
    "    def __init__(self, dataset_path, base_config, username='reddy.bathula'):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.base_config = base_config\n",
    "        self.best_model = None\n",
    "        self.best_auc = -1\n",
    "        self.best_fpr = None\n",
    "        self.best_tpr = None\n",
    "        self.best_thresholds = None\n",
    "        self.threshold = None\n",
    "        self.username = username\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Private method to load and preprocess the LFW dataset from a folder structure.\"\"\"\n",
    "        all_images, all_labels = [], []\n",
    "        normal_class_name = 'George_W_Bush'\n",
    "        \n",
    "        for person_name in os.listdir(self.dataset_path):\n",
    "            person_folder = os.path.join(self.dataset_path, person_name)\n",
    "            if not os.path.isdir(person_folder): continue\n",
    "            is_normal = (person_name == normal_class_name)\n",
    "            for image_filename in os.listdir(person_folder):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(person_folder, image_filename)).convert('L')\n",
    "                    all_images.append(np.array(img))\n",
    "                    all_labels.append(0 if is_normal else 1)\n",
    "                except Exception:\n",
    "                    continue\n",
    "                    \n",
    "        permutation = np.random.permutation(len(all_images))\n",
    "        all_images = [all_images[i] for i in permutation]\n",
    "        all_labels = [all_labels[i] for i in permutation]\n",
    "\n",
    "        X = np.array(all_images)\n",
    "        y = np.array(all_labels)\n",
    "        self.image_shape = X.shape[1:]\n",
    "        X_flattened = X.reshape(len(X), -1).astype('float32') / 255.0\n",
    "\n",
    "        self.X_train_normal = X_flattened[y == 0]\n",
    "        self.X_test = X_flattened\n",
    "        self.y_test_anomaly = y\n",
    "\n",
    "    def _train_model(self, autoencoder):\n",
    "        \"\"\"Helper method to run the training loop for a given autoencoder.\"\"\"\n",
    "        for epoch in range(self.base_config[\"epochs\"]):\n",
    "            pbar = tqdm(range(0, len(self.X_train_normal), self.base_config[\"batch_size\"]),\n",
    "                        desc=f\"Epoch {epoch+1}/{self.base_config['epochs']}\", leave=False)\n",
    "            for i in pbar:\n",
    "                x_batch = self.X_train_normal[i: i + self.base_config[\"batch_size\"]]\n",
    "                loss = autoencoder.train_step(x_batch, self.base_config[\"learning_rate\"])\n",
    "                pbar.set_postfix({\"loss\": f\"{loss:.4f}\"})\n",
    "        gc.collect()\n",
    "\n",
    "    def run_bottleneck_analysis(self, bottleneck_dims):\n",
    "        \"\"\" Investigates how the bottleneck dimension affects performance by training a model for each dimension and plotting their ROC curves. \"\"\"\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        for latent_dim in bottleneck_dims:\n",
    "            autoencoder = MLPAutoencoder(\n",
    "                input_dim=self.X_test.shape[1],\n",
    "                latent_dim=latent_dim,\n",
    "                hidden_dims=[256, 128]\n",
    "            )\n",
    "            self._train_model(autoencoder)\n",
    "            \n",
    "            errors = self._get_reconstruction_errors(autoencoder, self.X_test)\n",
    "            fpr, tpr, thresholds = roc_curve(self.y_test_anomaly, errors)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "\n",
    "            if auc_score > self.best_auc:\n",
    "                self.best_auc = auc_score\n",
    "                self.best_model = autoencoder\n",
    "                self.best_fpr = fpr\n",
    "                self.best_tpr = tpr\n",
    "                self.best_thresholds = thresholds\n",
    "\n",
    "            plt.plot(fpr, tpr, lw=2, label=f'Bottleneck={latent_dim} (AUC = {auc_score:.2f})')\n",
    "\n",
    "            del autoencoder\n",
    "            gc.collect()\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve Comparison for Different Bottleneck Dimensions')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"roc_curve_comparison.png\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    def evaluate_best_model(self):\n",
    "        \"\"\" Evaluates the best-performing model from the analysis, calculating and reporting the required anomaly detection metrics. \"\"\"\n",
    "        if not self.best_model:\n",
    "            raise RuntimeError(\"You must run bottleneck analysis before evaluating.\")\n",
    "        \n",
    "        # Calculate F1-score for each threshold\n",
    "        errors = self._get_reconstruction_errors(self.best_model, self.X_test)\n",
    "        f1_scores = []\n",
    "        for thresh in self.best_thresholds:\n",
    "            y_pred = (errors > thresh).astype(int)\n",
    "            f1 = f1_score(self.y_test_anomaly, y_pred, average='binary')\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        # Select threshold with maximum F1-score\n",
    "        best_f1_idx = np.argmax(f1_scores)\n",
    "        self.threshold = self.best_thresholds[best_f1_idx]\n",
    "        \n",
    "        y_pred_anomaly = (errors > self.threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(self.y_test_anomaly, y_pred_anomaly, average='binary')\n",
    "\n",
    "        print(f\"\\n--- Best Model Anomaly Detection Prformance ---\")\n",
    "        print(f\"Chosen Threshold (Max F1): {self.threshold:.4f}\")\n",
    "        print(f\"AUC Score: {self.best_auc:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    def _watermark(self, ax):\n",
    "        \"\"\"Adds a watermark to the plot axis.\"\"\"\n",
    "        ax.text(0.98, 0.98, self.username, ha='right', va='top', \n",
    "        transform=ax.transAxes, fontsize=10, color='black', alpha=0.6)\n",
    "\n",
    "    def visualize_best_model_results(self):\n",
    "        \"\"\"\n",
    "        Provides a comprehensive visualization of the best model's results, including classification examples and the PR curve. [cite: 298, 301]\n",
    "        \"\"\"\n",
    "        if not self.best_model:\n",
    "            raise RuntimeError(\"You must run bottleneck analysis before visualizing.\")\n",
    "\n",
    "        errors = self._get_reconstruction_errors(self.best_model, self.X_test)\n",
    "        y_pred_anomaly = (errors > self.threshold).astype(int)\n",
    "        self._plot_classification_examples(y_pred_anomaly, errors)\n",
    "        self._plot_pr_curve(errors)\n",
    "\n",
    "    def _get_reconstruction_errors(self, autoencoder, data):\n",
    "        \"\"\"Private helper to calculate MSE reconstruction error for each sample.\"\"\"\n",
    "        reconstructed = autoencoder.forward(data)\n",
    "        return np.mean((data - reconstructed)**2, axis=1)\n",
    "\n",
    "    def _plot_classification_examples(self, y_pred_anomaly, errors):\n",
    "        \"\"\"Helper to find and plot examples of correct and incorrect classifications.\"\"\"\n",
    "        cases = {\n",
    "            \"True Negative (Correctly Normal)\": np.where((self.y_test_anomaly == 0) & (y_pred_anomaly == 0))[0],\n",
    "            \"True Positive (Correctly Anomaly)\": np.where((self.y_test_anomaly == 1) & (y_pred_anomaly == 1))[0],\n",
    "            \"False Positive (Normal as Anomaly)\": np.where((self.y_test_anomaly == 0) & (y_pred_anomaly == 1))[0],\n",
    "            \"False Negative (Anomaly as Normal)\": np.where((self.y_test_anomaly == 1) & (y_pred_anomaly == 0))[0],\n",
    "        }\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(8, 16))\n",
    "        fig.suptitle(\"Anomaly Detection Examples\", fontsize=20)\n",
    "\n",
    "        for i, (title, indices) in enumerate(cases.items()):\n",
    "            if len(indices) == 0:\n",
    "                axes[i, 0].set_title(f\"{title}\\n(No examples found)\")\n",
    "                axes[i, 0].axis('off')\n",
    "                axes[i, 1].axis('off')\n",
    "                continue\n",
    "            \n",
    "            idx = indices[0]\n",
    "            original_img = self.X_test[idx].reshape(self.image_shape)\n",
    "            reconstructed_img = self.best_model.forward(self.X_test[idx].reshape(1, -1)).reshape(self.image_shape)\n",
    "            error = errors[idx]\n",
    "            error_map = (original_img - reconstructed_img)**2\n",
    "\n",
    "            axes[i, 0].imshow(original_img, cmap='gray')\n",
    "            axes[i, 0].set_title(f\"{title}\\nOriginal Image\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(reconstructed_img, cmap='gray')\n",
    "            axes[i, 1].set_title(f\"Reconstructed Image\\n Error: {error:.4f}\")\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "            im = axes[i, 2].imshow(error_map, cmap='hot')\n",
    "            axes[i, 2].set_title(f\"Reconstruction Error: {error:.4f}\")\n",
    "            axes[i, 2].axis('off')\n",
    "            fig.colorbar(im, ax=axes[i, 2])\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        self._watermark(plt.gca())\n",
    "        plt.savefig(\"anomaly_examples.png\")\n",
    "        plt.show()\n",
    "        return\n",
    " \n",
    "    \n",
    "    def _plot_pr_curve(self, errors):\n",
    "        \"\"\"Helper to plot the Precision-Recall curve.\"\"\"\n",
    "        precisions, recalls, _ = precision_recall_curve(self.y_test_anomaly, errors)\n",
    "        plt.figure(figsize=(8, 6)); plt.plot(recalls, precisions, lw=2)\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(\"Precision-Recall Curve for Best Model\")\n",
    "        self._watermark(plt.gca())\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"pr_curve.png\")\n",
    "        plt.show()\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Runs the full anomaly detection pipeline: training, bottleneck analysis, evaluation, and visualization.\"\"\"\n",
    "        self.run_bottleneck_analysis(bottleneck_dims=[32, 64, 128])\n",
    "        self.evaluate_best_model()\n",
    "        self.visualize_best_model_results()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960f367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset_path = '/home/detour/Documents/SMAI/Assignments/assignment3/Datasets/LFW_Dataset/'\n",
    "username = 'reddy.bathula'\n",
    "config = [{\"learning_rate\": 0.001, \"epochs\": 200, \"batch_size\": 64}]\n",
    "for base_config in config:\n",
    "    detector = AnomalyDetector(dataset_path, base_config, username)\n",
    "    detector.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14535ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
